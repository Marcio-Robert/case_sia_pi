# Bibliotecas
import streamlit as st
import pandas as pd
import re
from wordcloud import WordCloud
import matplotlib.pyplot as plt
import plotly.express as px
import nltk
from nltk.corpus import stopwords

# --- DOWNLOAD DAS STOPWORDS (sÃ³ acontece na primeira vez) ---
try:
    stopwords.words('portuguese')
except LookupError:
    st.info("Baixando recursos de linguagem necessÃ¡rios (stopwords). Isso sÃ³ acontece uma vez.")
    nltk.download('stopwords')

# --- CONFIGURAÃ‡ÃƒO DA PÃGINA ---
st.set_page_config(
    page_title="Monitor de PercepÃ§Ã£o sobre IA no PiauÃ­",
    page_icon="ðŸ¤–",
    layout="wide"
)

# --- FUNÃ‡Ã•ES ---

# Carregar os dados


@st.cache_data
def carregar_dados(caminho_arquivo):
    try:
        df = pd.read_csv(caminho_arquivo)
        return df
    except FileNotFoundError:
        st.error(
            f"Erro: O arquivo '{caminho_arquivo}' nÃ£o foi encontrado. Execute o script 'coleta_noticias.py' primeiro.")
        return None

# Limpar textos simples


def limpar_texto(texto):
    # Pegando a lista nltk
    stopwords_pt = stopwords.words('portuguese')
    # Adicionando palavras sem valor
    stopwords_pt.extend(['piauÃ­', 'teresina', 'marcio',
                        'robert', 'sobre', 'terÃ¡', 'ainda', 'diz'])

    texto = texto.lower()
    texto = re.sub(r'[^a-zA-Z\s]', '', texto)
    palavras = [palavra for palavra in texto.split()
                if palavra not in stopwords_pt]
    return " ".join(palavras)

# Analisar sentimento baseado em regras


def analisar_sentimento(texto, palavras_positivas, palavras_negativas):
    score = 0
    palavras = texto.split()
    for palavra in palavras:
        if palavra in palavras_positivas:
            score += 1
        elif palavra in palavras_negativas:
            score -= 1

    if score > 0:
        return 'Positivo'
    elif score < 0:
        return 'Negativo'
    else:
        return 'Neutro'

# --- LÃ“GICA PRINCIPAL DO DASHBOARD ---


# TÃ­tulo
st.title("ðŸ¤– Monitor de PercepÃ§Ã£o PÃºblica sobre IA no PiauÃ­")
st.markdown("Dashboard simplificado para monitorar menÃ§Ãµes sobre 'InteligÃªncia Artificial no PiauÃ­' em fontes de notÃ­cias pÃºblicas.")

# Carregando dados
df_noticias = carregar_dados('noticias.csv')

if df_noticias is not None:
    # Processamento do case
    # Limpando os tÃ­tulos para anÃ¡lise
    df_noticias['titulo_limpo'] = df_noticias['titulo'].apply(limpar_texto)

    # Criando listas de palavras para anÃ¡lise de sentimento
    palavras_positivas = [
        'avanÃ§o', 'crescimento', 'inova', 'desenvolvimento', 'oportunidade', 'melhora', 'beneficia', 'investimento',
        'soluÃ§Ã£o', 'positivo', 'expansÃ£o', 'parceria', 'fortalece', 'impulso', 'moderniza', 'otimiza', 'eficiÃªncia',
        'qualidade', 'aprimora', 'incentivo', 'fomento', 'sucesso', 'destaque', 'potencial'
    ]
    palavras_negativas = [
        'risco', 'perigo', 'problema', 'desemprego', 'crise', 'ameaÃ§a', 'negativo', 'corte', 'dificuldade',
        'preocupaÃ§Ã£o', 'alerta', 'impacto', 'desafio', 'fraude', 'golpe', 'ilegal', 'atraso', 'falha', 'inseguranÃ§a',
        'vulnerabilidade', 'prejuÃ­zo', 'polÃªmica'
    ]
    # Aplicando a anÃ¡lise de sentimento
    df_noticias['sentimento'] = df_noticias['titulo_limpo'].apply(
        lambda texto: analisar_sentimento(texto, palavras_positivas, palavras_negativas))

    # --- VisualizaÃ§Ã£o do case ---
    st.header("AnÃ¡lise de Sentimento das NotÃ­cias")

    # Layout em duas colunas para os grÃ¡ficos
    col1, col2 = st.columns(2)

    with col1:
        # GrÃ¡fico de Pizza com a distribuiÃ§Ã£o de sentimentos
        sentimento_counts = df_noticias['sentimento'].value_counts()
        fig_pie = px.pie(
            sentimento_counts,
            values=sentimento_counts.values,
            names=sentimento_counts.index,
            title="DistribuiÃ§Ã£o de Sentimentos",
            color=sentimento_counts.index,
            color_discrete_map={'Positivo': 'green',
                                'Negativo': 'red', 'Neutro': 'blue'}
        )
        st.plotly_chart(fig_pie, use_container_width=True)

    with col2:
        # Nuvem de palavras com os termos mais frequentes
        st.subheader("Nuvem de Palavras-Chave")
        texto_completo = " ".join(
            titulo for titulo in df_noticias['titulo_limpo'])

        # Gerar a nuvem de palavras se houver texto
        if texto_completo.strip():
            wordcloud = WordCloud(
                background_color="white",
                width=800,
                height=400,
                colormap='viridis',
                max_words=100
            ).generate(texto_completo)

            fig_wc, ax = plt.subplots()
            ax.imshow(wordcloud, interpolation='bilinear')
            ax.axis("off")
            st.pyplot(fig_wc)
        else:
            st.write("NÃ£o hÃ¡ texto suficiente para gerar a nuvem de palavras.")

    # Tabela interativa com os dados coletados e classificados
    st.header("Detalhes das NotÃ­cias Coletadas")
    st.dataframe(
        df_noticias[['titulo', 'sentimento', 'link', 'descricao']],
        column_config={
            "link": st.column_config.LinkColumn(
                "Link da NotÃ­cia",
                help="Clique para abrir a notÃ­cia original em uma nova aba"
            )
        },
        hide_index=True
    )
    # --- Ã‰tica e TransparÃªncia do case ---
    st.markdown("---")
    st.caption("Esta anÃ¡lise de sentimento Ã© baseada em regras simples e pode nÃ£o capturar sarcasmo ou contextos complexos. O objetivo Ã© oferecer uma visÃ£o geral e automatizada da percepÃ§Ã£o pÃºblica.")
